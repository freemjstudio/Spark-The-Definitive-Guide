# 개요
* 아파치 스파크는 "통합 컴퓨팅 엔진"이며 클러스터 환경에서 "데이터를 병렬로 처리"하는 라이브러리 집합이다.
* 현재 스파크는 병럴 처리 오픈소스 엔진으로 개발자나 분석가들에게 인기가 많다.
* Python, Java, Scala, R을 지원하며 SQL 뿐만 아니라 스트리밍, 머신러닝 등 다양한 범위의 라이브러리를 제공하고 있다.
* 이번 단원에서는 스파크의 역사와 스파크 실행에 필요한 몇 가지 기초사항을 소개한다.

# 1.1 아파치 스파크의 철학
* "통합" 컴퓨팅 엔진
  * 스파크는 여러 통합 플랫폼과 유사한 사용 방식을 제공한다.
  * 스파크는 통합 엔진을 제공하면서 빅데이터 분석 업무의 표준이 되었다.
  * 현재도 스파크 프로젝트 개발자들이 개발을 많이 하고 있으며 다듬고 있다고 한다.
  * 해당 책에서는 스파크 2.9 버전을 기반으로 API 소개를 한다.
* 통합 "컴퓨팅 엔진"
  * 스파크는 기능어 범위를 컴퓨팅 엔진으로 제한해왔다. 
  * 즉, 데이터를 대상으로 연산만 할 뿐 저장을 하지는 않는다.
  * 대신 Azure, S3, Hadoop, Cassandra, Kafka 등의 저장소를 지원한다.
* 라이브러리
  * 스파크는 엔진에서 제공하는 표준 라이브러리와 오픈소스 커뮤니티에 서드파티 패키지 형태로 제공하는 외부 라이브러리들도 지원하고 있다.
  * 스파크는 Spark SQL, MLlib, Spark Streaming, GraphX 라이브러리를 제공하고 있다.
  * 이 외에도 다양한 오픈소스 라이브러리들이 존재한다. (참고: spark-packages.org)

# 1.2 스파크의 등장 배경
* 단일 프로세서의 성능 향상 한계 
  * 2005년 이후 하드웨어의 성능 향상이 멈추고 병렬 CPU 코어 추가가 주를 이루게 되면서 애플리케이션의 성능 향상을 위해 병렬 처리가 필요하게 되었다. 
    * 이로 인해 새로운 프로그래밍 모델이 필요하게 되었다.
* 데이터 저장과 수집 기술의 발전 
  * 프로세서 속도가 개선되지 않은 반면, 데이터 저장과 수집 기술은 계속해서 발전 
  * 이로 인해 대량의 데이터를 저렴하게 저장하고, 다양한 종류의 데이터(영상, 센서 데이터 등)를 수집하는 것이 가능 
* 거대한 데이터 처리의 필요성 
  * 데이터 수집 비용이 저렴해지고, 수집되는 데이터의 양이 증가함에 따라 데이터 처리에 필요한 클러스터의 크기도 커져야 했다. 
  * 이로 인해 기존의 프로그래밍 모델로는 더 이상 성능 향상을 이룰 수 없게 되어, 새로운 프로그래밍 모델인 아파치 스파크가 등장

# 1.3 스파크의 역사
* UC 버클리대학교에서 2009년 스파크 연구 프로젝트로 최초 시작 
* 맵리듀스의 한계를 극복하기 위해서 함수형 프로그래밍 기반의 API 설계 
* 첫 번째 버전은 배치 애플리케이션만 지원하였는데 이후 대화형 데이터 분석이나 비정형(ad-hoc) 쿼리 같은 기능을 추가적으로 제공 
* 현재도 표준 라이브러리 형태의 구현 방식을 유지하며 여러 그룹이 다양한 라이브러리를 만들기 시작 
* 1.0 이전의 초기 버전에서는 함수형 연산 관점에서 API를 정의 
* 1.0 이후의 버전에서는 구조화된 데이터를 기반으로 동작하는 스파크 SQL API를 추가로 정의 
* 이후 데이터프레임, 머신러닝 파이프라인, 구조적 스트리밍 등 다양한 신규 API를 추가

# 1.4 스파크의 현재와 미래
* 스파크는 꾸준한 인기를 얻고 있으며 영역 또한 넓혀가고 있다.
* 2016년에 고수준 스트리밍 엔진인 구조적 스트리밍 소개를 하였다.
* Uber, Netfilx 같은 기업이나 NASA, CERN 같은 연구소에서 거대한 규모의 데이터 처리를 위해 사용하고 있다.

# 1.5 스파크 실행하기
## 1.5.1 로컬 환경에 스파크를 내려받아서 실행하기
* 자바가 설치되어 있어야 한다. 파이썬으로 스파크를 사용하려면 파이썬 버전도 확인한다.
* 스파크 프로젝트 공식 홈페이지에서 타르볼(.tgz) 파일을 다운로드 받고 압축 해제한다.
## 1.5.2 스파크 대화형 콘솔 실행하기
* bin 디렉토리에 언어에 맞는 인터프리터를 실행한다. (*/bin/spark 혹은 */bin/spark-shell)
## 1.5.3 클라우드에서 스파크 실행하기
* 데이터브릭스 커뮤니티 에디션을 사용하면 된다. (자세한 설명은 생략)

# 1.6 정리
- 스파크의 개요와 탄생 배경 그리고 환경 구성하는 방법을 살펴보았다.