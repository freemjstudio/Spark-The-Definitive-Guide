# 개요
아파치 스파크는 **통합 컴퓨팅 엔진**이며 클러스터 환경에서 **데이터를 병렬로 처리**하는 라이브러리 집합
스파크는 가장 활발하게 개발되고 있는 병렬 처리 오픈소스 엔진이며 빅데이터에 관심이 있는 개발자, 데이터 사이언티스트에게 표준 도구가 되어가고 있다.
파이썬, 자바, 스칼라, R을 지원하며 SQL 뿐만 아니라 스트리밍, 머신러닝 등 라이브러리를 제공
스파크는 Scale up 이 쉬운편
  
# 1.1 아파치 스파크의 철학
* 통합
	- "빅데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공하자" 라는 목표
	- 통합(unified)는 간단한 데이터 읽기에서부터 SQL, ML, streaming 처리에 이르기까지 다양한 분석작업을 수행할 수 있도록 설계
	- 개발 사상이 데이터 분석작업이 다양한 처리유형과 라이브러리를 결합하여 수행한다는 통찰에서 비롯됨
* 컴퓨팅 엔진
	- 통합이라는 관점을 중시하며, 기능을 컴퓨팅 엔진으로 제한
	- 별도 스토리지로써의 기능은 수행하지 않지만 Azure, S3, HDFS, Cassandra, Kafka 등의 스토리지를 지원
	- 애초부터 분산컴퓨팅 목적으로써, Hadoop 과 매우 밀접
* 라이브러리
	- 스파크는 엔진에서의 표준 라이브러리와 서드파티 패키지 형태의 다양한 외부 라이브러리를 지원하 (사실 스파크는 여러 오픈소스 프로젝트의 집합체)
	- Spark SQL, MLlib, Spark Streaming, GraphX 등과 같은 라이브러리를 지원하

# 1.2 스파크의 등장 배경
	- HW 성능 향상이 멈추면서, 결국엔 병렬 처리 엔진이 필요해 만들어지게 됨
	- Ingestion 은 빠르지만, 처리 비용에서 이를 따라가지 못하였고, 새로은 프로그래밍 모델로써 등장하게 되었다.
	
# 1.3 스파크의 역사
	- UC 버클리에서 2009년 스파크 연구 프로젝트로 시작
	- MR의 난이도와 효율성의 문제로 함수형 프로그래밍 기반의 API를 설계
	- In-Memory 기반의 API를 구현
	- 첫 번째 버전은 배치만 지원하였지만, 이후 대화형 분석, 비정형(ad-hoc) 쿼리와 같은 강력한 기능을 제공
	- 표준 라이브러리 형태의 구현 방식을 기점으로 MLlib, Streaming, GraphX와 같은 여러 처리 유형을 결합할 수 있는 앱을 개발할 수 있게 됨
	- 초기버전은 함수형 연산관점에서 API 정의 이후로는 구조화된 데이터를 기반으로 동작하는 Spark SQL이 추가
	- 그 이후 DataFrame, ML, 구조적 스트리밍 등 강력한 구조체 기반의 신규 API 추가
	
# 1.4 스파크의 현재와 미래
	- 지속적인 인기와 활용 사례가 늘어나고 있으며, 생태계 확장 중에 있음
	- 2016년 고수준 스트리밍 엔진을 소개하였고, 우버 / 넷플릭스 / NASA / CERN 등에서 사용 중

# 1.5 스파크 실행하기
	- Spark 공홈 이용 / 우리는 데이터 브릭스 커뮤니티 에디션 사용
	
# 1.6 정리
	- 스파크의 개요와 탄생배경, 환경구성을 다룬 1장이었다.
Data bricks Community Edition
